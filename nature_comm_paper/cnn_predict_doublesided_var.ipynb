{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/bryan/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "from keras import backend as K\n",
    "tf.set_random_seed(1)\n",
    "sess = tf.Session(graph=tf.get_default_graph())\n",
    "K.set_session(sess)\n",
    "import sys \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.regularizers\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import cPickle as pickle\n",
    "import collections\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "from video_process_utils import *\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_col = 'SEMLS_dev_residual'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata_processed =\\\n",
    "    pd.read_csv(\"data/annotations/alldata_processed_with_dev_residual.csv\" )\n",
    "alldata_processed['videoid'] = alldata_processed['videoid'].apply(lambda x: int(x))\n",
    "alldata_processed['target_count'] = alldata_processed.groupby('videoid')[target_col].transform(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata_processed = alldata_processed[alldata_processed[target_col].notnull()]\n",
    "alldata_processed = alldata_processed[alldata_processed['target_count'] == 2]\n",
    "ids_nonmissing_target = set(alldata_processed['videoid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datasplit_df = pd.read_csv('./data/train_test_valid_id_split.csv')\n",
    "datasplit_df['videoid'] = datasplit_df['videoid'].apply(lambda x: int(x))\n",
    "all_ids = set(datasplit_df['videoid']).intersection(ids_nonmissing_target)\n",
    "train_ids = set(datasplit_df[datasplit_df['dataset'] == 'train']['videoid']).intersection(ids_nonmissing_target)\n",
    "validation_ids = set(datasplit_df[datasplit_df['dataset'] == 'validation']['videoid']).intersection(ids_nonmissing_target)\n",
    "test_ids = set(datasplit_df[datasplit_df['dataset'] == 'test']['videoid']).intersection(ids_nonmissing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./data/all_processed_video_segments.pickle', 'r') as handle:\n",
    "    processed_video_segments = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(np.sum(alldata_processed[target_col].isnull()) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_columns_left = [2*LANK,2*LANK+1,2*LKNE,2*LKNE+1,\n",
    "        2*LHIP,2*LHIP+1,2*LBTO,2*LBTO+1,50,52,54,56]\n",
    "x_columns_right = [2*RANK,2*RANK+1,2*RKNE,2*RKNE+1,\n",
    "        2*RHIP,2*RHIP+1,2*RBTO,2*RBTO+1,51,53,55,57]\n",
    "\n",
    "target_dict_L = {}\n",
    "target_dict_R = {}\n",
    "for i in range(len(alldata_processed)):\n",
    "    row = alldata_processed.iloc[i]\n",
    "    if row['side'] == 'L':\n",
    "        target_dict_L[row['videoid']] = row[target_col]\n",
    "    if row['side'] == 'R':\n",
    "        target_dict_R[row['videoid']] = row[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [t[2] for t in processed_video_segments if t[0] in all_ids]\n",
    "X = np.stack(X)\n",
    "X = np.concatenate([X[:,:,x_columns_left],X[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = [t[2] for t in processed_video_segments if t[0] in train_ids]\n",
    "X_train = np.stack(X_train)\n",
    "X_train = np.concatenate([X_train[:,:,x_columns_left],X_train[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validation = [t[2] for t in processed_video_segments if t[0] in validation_ids]\n",
    "X_validation = np.stack(X_validation)\n",
    "X_validation = np.concatenate([X_validation[:,:,x_columns_left],X_validation[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "y_train_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "y_train = np.array(y_train_L + y_train_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_validation_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "y_validation_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "y_validation = np.array(y_validation_L + y_validation_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in all_ids]\n",
    "y_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in all_ids]\n",
    "y = np.array(y_L + y_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "videoid_count_dict = collections.Counter(np.array([t[0] for t in processed_video_segments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "train_videoid_weights = train_videoid_weights + train_videoid_weights\n",
    "train_videoid_weights = np.array(train_videoid_weights).reshape(-1,1)\n",
    "validation_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "validation_videoid_weights = validation_videoid_weights + validation_videoid_weights\n",
    "validation_videoid_weights = np.array(validation_videoid_weights).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_min = np.min(y_train,axis=0)\n",
    "target_range = np.max(y_train,axis=0) - np.min(y_train,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_scaled = ((y_train-target_min)/target_range).reshape(-1,1)\n",
    "y_validation_scaled = ((y_validation-target_min)/target_range).reshape(-1,1)\n",
    "y_validation_scaled = np.hstack([y_validation_scaled,validation_videoid_weights])\n",
    "y_train_scaled = np.hstack([y_train_scaled,train_videoid_weights])\n",
    "#c_i_factor is just a constant initially introduced to make the loss function more interpretable, but\n",
    "#is probably not necessary if the model were to be retrained\n",
    "c_i_factor = np.mean(np.vstack([train_videoid_weights,validation_videoid_weights])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vid_length = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bryan/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(32, 8, padding=\"same\", input_shape=(124, 12))`\n"
     ]
    }
   ],
   "source": [
    "def step_decay(initial_lrate,epochs_drop,drop_factor):\n",
    "    def step_decay_fcn(epoch):\n",
    "        return initial_lrate * math.pow(drop_factor, math.floor((1+epoch)/epochs_drop))\n",
    "    return step_decay_fcn\n",
    "\n",
    "epochs_drop,drop_factor = (10,0.8)\n",
    "initial_lrate = 0.001\n",
    "dropout_amount = 0.5\n",
    "last_layer_dim = 10\n",
    "filter_length = 8\n",
    "conv_dim = 32\n",
    "l2_lambda = 10**(-3.5)\n",
    "\n",
    "def w_mse(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.sum(K.square(y_true-y_pred)*weights,axis=1)*tf.reshape(y_true[:,-1],(-1,1)))/c_i_factor\n",
    "    return loss\n",
    "\n",
    "#we don't want to optimize for the column counting video occurences, but\n",
    "#they are included in the target so we can use that column for the loss function\n",
    "weights = [1.0,0]\n",
    "\n",
    "#fixed epoch budget of 100 that empirically seems to be sufficient \n",
    "n_epochs = 100\n",
    "\n",
    "mse_opt = w_mse(weights)\n",
    "\n",
    "#this is just for monitoring\n",
    "mse_metric = w_mse(target_range**2*np.array(weights))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv_dim,filter_length, input_dim=X_train.shape[2],input_length=vid_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(last_layer_dim,activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoint_folder = \"/home/bryan/clinical-video/cnn_checkpoints_%s\" % (target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_model = True\n",
    "\n",
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "filepath=checkpoint_folder+\"/weights-{epoch:02d}-{val_loss_2:.4f}.hdf5\"\n",
    "if train_model:\n",
    "\n",
    "    opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=mse_opt,metrics=[mse_metric],\n",
    "                  optimizer=opt)\n",
    "\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, monitor='val_loss_2', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    history = model.fit(X_train, y_train_scaled,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "              validation_data=(X_validation,y_validation_scaled),\n",
    "              batch_size=32, epochs=n_epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undo_scaling(y,target_range,target_min):\n",
    "    return y*target_range+target_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weight_files = os.listdir(checkpoint_folder)\n",
    "weight_files_df = pd.DataFrame(weight_files,columns=['filename'])\n",
    "weight_files_df['num'] = weight_files_df['filename'].apply(lambda x: int(x.split('-')[1]))\n",
    "weight_files_df.sort_values(by='num',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#todo: change so we also have a X,y for all_ids\n",
    "#then for each of 100 epochs, generate the predictions of the model for each epoch\n",
    "#this dataframe can then be saved, and a file called \"get_best_epoch\" can be used to generate the best one\n",
    "#(video_id,target,predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_and_aggregate(y,X,ids,model,target_col):\n",
    "    df = pd.DataFrame(y,columns=[target_col])\n",
    "    side_col = ['L' if i < len(df)/2 else 'R' for i in range(len(df))]\n",
    "    target_col_pred = target_col + \"_pred\"\n",
    "    videoids = [t[0] for t in processed_video_segments if t[0] in ids]\n",
    "    videoids = videoids + videoids\n",
    "    df[\"videoid\"] = np.array(videoids)\n",
    "    df['side'] = side_col\n",
    "    preds = model.predict(X)\n",
    "    df[target_col_pred] = undo_scaling(preds[:,0],target_range,target_min)\n",
    "    df[\"count\"] = 1\n",
    "    df = df.groupby(['videoid','side'],as_index=False).agg({target_col_pred:np.mean,'count':np.sum,target_col:np.mean})\n",
    "    df['ones'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "video_ids = [t[0] for t in processed_video_segments if t[0] in all_ids]\n",
    "video_ids = video_ids + video_ids\n",
    "predictions_df = pd.DataFrame(video_ids,columns=['videoid'])\n",
    "side_col = ['L' if i < len(predictions_df)/2 else 'R' for i in range(len(predictions_df))]\n",
    "predictions_df[target_col] = y\n",
    "predictions_df['side'] = side_col\n",
    "predictions_df = predictions_df.merge(right=datasplit_df[['videoid','dataset']],on=['videoid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights-00-86.4237.hdf5\n",
      "weights-01-98.9111.hdf5\n",
      "weights-02-87.3220.hdf5\n",
      "weights-03-85.8565.hdf5\n",
      "weights-04-91.1653.hdf5\n",
      "weights-05-80.9056.hdf5\n",
      "weights-06-72.2637.hdf5\n",
      "weights-07-59.8240.hdf5\n",
      "weights-08-67.0776.hdf5\n",
      "weights-09-60.6945.hdf5\n",
      "weights-10-70.8957.hdf5\n",
      "weights-11-62.5470.hdf5\n",
      "weights-12-65.3806.hdf5\n",
      "weights-13-66.4281.hdf5\n",
      "weights-14-73.1030.hdf5\n",
      "weights-15-60.8615.hdf5\n",
      "weights-16-64.0410.hdf5\n",
      "weights-17-62.3888.hdf5\n",
      "weights-18-60.2654.hdf5\n",
      "weights-19-72.5628.hdf5\n",
      "weights-20-62.0319.hdf5\n",
      "weights-21-63.2341.hdf5\n",
      "weights-22-72.9835.hdf5\n",
      "weights-23-64.8781.hdf5\n",
      "weights-24-64.4222.hdf5\n",
      "weights-25-72.8902.hdf5\n",
      "weights-26-60.4510.hdf5\n",
      "weights-27-66.1328.hdf5\n",
      "weights-28-58.3316.hdf5\n",
      "weights-29-64.2199.hdf5\n",
      "weights-30-63.4656.hdf5\n",
      "weights-31-62.6747.hdf5\n",
      "weights-32-59.5008.hdf5\n",
      "weights-33-62.0990.hdf5\n",
      "weights-34-64.9120.hdf5\n",
      "weights-35-62.6186.hdf5\n",
      "weights-36-59.0109.hdf5\n",
      "weights-37-62.5512.hdf5\n",
      "weights-38-59.0609.hdf5\n",
      "weights-39-61.5603.hdf5\n",
      "weights-40-69.5490.hdf5\n",
      "weights-41-56.3450.hdf5\n",
      "weights-42-60.9818.hdf5\n",
      "weights-43-57.3913.hdf5\n",
      "weights-44-60.8836.hdf5\n",
      "weights-45-63.9856.hdf5\n",
      "weights-46-60.1661.hdf5\n",
      "weights-47-63.5977.hdf5\n",
      "weights-48-61.6902.hdf5\n",
      "weights-49-62.2065.hdf5\n",
      "weights-50-62.3523.hdf5\n",
      "weights-51-60.5734.hdf5\n",
      "weights-52-62.7061.hdf5\n",
      "weights-53-57.2431.hdf5\n",
      "weights-54-60.9853.hdf5\n",
      "weights-55-61.2267.hdf5\n",
      "weights-56-61.8191.hdf5\n",
      "weights-57-61.4357.hdf5\n",
      "weights-58-58.0455.hdf5\n",
      "weights-59-59.1920.hdf5\n",
      "weights-60-58.5087.hdf5\n",
      "weights-61-57.3453.hdf5\n",
      "weights-62-59.9888.hdf5\n",
      "weights-63-56.5822.hdf5\n",
      "weights-64-57.3261.hdf5\n",
      "weights-65-60.3153.hdf5\n",
      "weights-66-57.1912.hdf5\n",
      "weights-67-58.0212.hdf5\n",
      "weights-68-57.6988.hdf5\n",
      "weights-69-58.1143.hdf5\n",
      "weights-70-58.6124.hdf5\n",
      "weights-71-57.3112.hdf5\n",
      "weights-72-60.0702.hdf5\n",
      "weights-73-60.5887.hdf5\n",
      "weights-74-57.1466.hdf5\n",
      "weights-75-58.6964.hdf5\n",
      "weights-76-58.2424.hdf5\n",
      "weights-77-57.5944.hdf5\n",
      "weights-78-56.0606.hdf5\n",
      "weights-79-57.0923.hdf5\n",
      "weights-80-56.6963.hdf5\n",
      "weights-81-56.9147.hdf5\n",
      "weights-82-58.3924.hdf5\n",
      "weights-83-58.6784.hdf5\n",
      "weights-84-57.0541.hdf5\n",
      "weights-85-57.7335.hdf5\n",
      "weights-86-58.9213.hdf5\n",
      "weights-87-58.3289.hdf5\n",
      "weights-88-57.9369.hdf5\n",
      "weights-89-57.0270.hdf5\n",
      "weights-90-59.3988.hdf5\n",
      "weights-91-58.4085.hdf5\n",
      "weights-92-58.3933.hdf5\n",
      "weights-93-58.1387.hdf5\n",
      "weights-94-57.7616.hdf5\n",
      "weights-95-59.3846.hdf5\n",
      "weights-96-56.7215.hdf5\n",
      "weights-97-56.9026.hdf5\n",
      "weights-98-56.5541.hdf5\n",
      "weights-99-58.0930.hdf5\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(weight_files_df)):\n",
    "    weight_file = weight_files_df['filename'].iloc[i]\n",
    "    print(weight_file)\n",
    "    model.load_weights(checkpoint_folder + \"/%s\" % (weight_file))\n",
    "    preds = model.predict(X)\n",
    "    predictions_df[\"%s_pred_%s\" % (target_col,i)] = undo_scaling(preds[:,0],target_range,target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_df.groupby(['videoid','side','dataset'],as_index=False).mean().to_csv(\"./predictions/cnn_%s_predictions_all_epochs.csv\" % (target_col),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "from keras import backend as K\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "#sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph())\n",
    "#K.set_session(sess)\n",
    "import sys \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.regularizers\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import pickle\n",
    "import collections\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "from video_process_utils import *\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'GDI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_processed =\\\n",
    "    pd.read_csv(\"data/processed/alldata_processed_with_dev_residual.csv\" )\n",
    "alldata_processed['videoid'] = alldata_processed['videoid'].apply(lambda x: int(x))\n",
    "alldata_processed['target_count'] = alldata_processed.groupby('videoid')[target_col].transform(lambda x: x.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata_processed = alldata_processed[alldata_processed[target_col].notnull()]\n",
    "alldata_processed = alldata_processed[alldata_processed['target_count'] == 2]\n",
    "ids_nonmissing_target = set(alldata_processed['videoid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_df = pd.read_csv('./data/processed/train_test_valid_id_split.csv')\n",
    "datasplit_df['videoid'] = datasplit_df['videoid'].apply(lambda x: int(x))\n",
    "all_ids = set(datasplit_df['videoid']).intersection(ids_nonmissing_target)\n",
    "train_ids = set(datasplit_df[datasplit_df['dataset'] == 'train']['videoid']).intersection(ids_nonmissing_target)\n",
    "validation_ids = set(datasplit_df[datasplit_df['dataset'] == 'validation']['videoid']).intersection(ids_nonmissing_target)\n",
    "test_ids = set(datasplit_df[datasplit_df['dataset'] == 'test']['videoid']).intersection(ids_nonmissing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/all_processed_video_segments.pickle', 'rb') as handle:\n",
    "    processed_video_segments = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.sum(alldata_processed[target_col].isnull()) == 0)\n",
    "alldata_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns_left = [2*LANK,2*LANK+1,2*LKNE,2*LKNE+1,\n",
    "        2*LHIP,2*LHIP+1,2*LBTO,2*LBTO+1,50,52,54,56]\n",
    "x_columns_right = [2*RANK,2*RANK+1,2*RKNE,2*RKNE+1,\n",
    "        2*RHIP,2*RHIP+1,2*RBTO,2*RBTO+1,51,53,55,57]\n",
    "\n",
    "target_dict_L = {}\n",
    "target_dict_R = {}\n",
    "for i in range(len(alldata_processed)):\n",
    "    row = alldata_processed.iloc[i]\n",
    "    if row['side'] == 'L':\n",
    "        target_dict_L[row['videoid']] = row[target_col]\n",
    "    if row['side'] == 'R':\n",
    "        target_dict_R[row['videoid']] = row[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [t[2] for t in processed_video_segments if t[0] in all_ids]\n",
    "X = np.stack(X)\n",
    "X = np.concatenate([X[:,:,x_columns_left],X[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [t[2] for t in processed_video_segments if t[0] in train_ids]\n",
    "X_train = np.stack(X_train)\n",
    "X_train = np.concatenate([X_train[:,:,x_columns_left],X_train[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = [t[2] for t in processed_video_segments if t[0] in validation_ids]\n",
    "X_validation = np.stack(X_validation)\n",
    "X_validation = np.concatenate([X_validation[:,:,x_columns_left],X_validation[:,:,x_columns_right]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "y_train_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "y_train = np.array(y_train_L + y_train_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "y_validation_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "y_validation = np.array(y_validation_L + y_validation_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_L = [target_dict_L[t[0]] for t in processed_video_segments if t[0] in all_ids]\n",
    "y_R = [target_dict_R[t[0]] for t in processed_video_segments if t[0] in all_ids]\n",
    "y = np.array(y_L + y_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoid_count_dict = collections.Counter(np.array([t[0] for t in processed_video_segments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "train_videoid_weights = train_videoid_weights + train_videoid_weights\n",
    "train_videoid_weights = np.array(train_videoid_weights).reshape(-1,1)\n",
    "validation_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "validation_videoid_weights = validation_videoid_weights + validation_videoid_weights\n",
    "validation_videoid_weights = np.array(validation_videoid_weights).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_min = np.min(y_train,axis=0)\n",
    "target_range = np.max(y_train,axis=0) - np.min(y_train,axis=0)\n",
    "print(target_min, target_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled = ((y_train-target_min)/target_range).reshape(-1,1)\n",
    "y_validation_scaled = ((y_validation-target_min)/target_range).reshape(-1,1)\n",
    "y_validation_scaled = np.hstack([y_validation_scaled,validation_videoid_weights])\n",
    "y_train_scaled = np.hstack([y_train_scaled,train_videoid_weights])\n",
    "#c_i_factor is just a constant initially introduced to make the loss function more interpretable, but\n",
    "#is probably not necessary if the model were to be retrained\n",
    "c_i_factor = np.mean(np.vstack([train_videoid_weights,validation_videoid_weights])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_length = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(initial_lrate,epochs_drop,drop_factor):\n",
    "    def step_decay_fcn(epoch):\n",
    "        return initial_lrate * math.pow(drop_factor, math.floor((1+epoch)/epochs_drop))\n",
    "    return step_decay_fcn\n",
    "\n",
    "epochs_drop,drop_factor = (10,0.8)\n",
    "initial_lrate = 0.001\n",
    "dropout_amount = 0.5\n",
    "last_layer_dim = 10\n",
    "filter_length = 8\n",
    "conv_dim = 32\n",
    "l2_lambda = 10**(-3.5)\n",
    "\n",
    "def w_mse(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        return K.mean(K.sum(K.square(y_true-y_pred)*weights,axis=1)*tf.reshape(y_true[:,-1],(-1,1)))/c_i_factor\n",
    "    return loss\n",
    "\n",
    "#we don't want to optimize for the column counting video occurences, but\n",
    "#they are included in the target so we can use that column for the loss function\n",
    "weights = [1.0,0]\n",
    "\n",
    "#fixed epoch budget of 100 that empirically seems to be sufficient \n",
    "n_epochs = 100\n",
    "\n",
    "mse_opt = w_mse(weights)\n",
    "\n",
    "#this is just for monitoring\n",
    "mse_metric = w_mse(target_range**2*np.array(weights))\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv_dim,filter_length, input_dim=X_train.shape[2],input_length=vid_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(last_layer_dim,activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = \"./data/checkpoints/cnn_checkpoints_%s\" % (target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_model = True\n",
    "\n",
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "filepath=checkpoint_folder+\"/weights-{epoch:02d}-{val_loss_1:.4f}.hdf5\"\n",
    "if train_model:\n",
    "\n",
    "    opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=mse_opt,metrics=[mse_metric],\n",
    "                  optimizer=opt)\n",
    "\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, monitor='val_loss_1', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    history = model.fit(X_train, y_train_scaled,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "              validation_data=(X_validation,y_validation_scaled),\n",
    "              batch_size=32, epochs=n_epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undo_scaling(y,target_range,target_min):\n",
    "    return y*target_range+target_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_files = os.listdir(checkpoint_folder)\n",
    "weight_files_df = pd.DataFrame(weight_files,columns=['filename'])\n",
    "weight_files_df['num'] = weight_files_df['filename'].apply(lambda x: int(x.split('-')[1]))\n",
    "weight_files_df.sort_values(by='num',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#todo: change so we also have a X,y for all_ids\n",
    "#then for each of 100 epochs, generate the predictions of the model for each epoch\n",
    "#this dataframe can then be saved, and a file called \"get_best_epoch\" can be used to generate the best one\n",
    "#(video_id,target,predictions,dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_aggregate(y,X,ids,model,target_col):\n",
    "    df = pd.DataFrame(y,columns=[target_col])\n",
    "    side_col = ['L' if i < len(df)/2 else 'R' for i in range(len(df))]\n",
    "    target_col_pred = target_col + \"_pred\"\n",
    "    videoids = [t[0] for t in processed_video_segments if t[0] in ids]\n",
    "    videoids = videoids + videoids\n",
    "    df[\"videoid\"] = np.array(videoids)\n",
    "    df['side'] = side_col\n",
    "    preds = model.predict(X)\n",
    "    df[target_col_pred] = undo_scaling(preds[:,0],target_range,target_min)\n",
    "    df[\"count\"] = 1\n",
    "    df = df.groupby(['videoid','side'],as_index=False).agg({target_col_pred:np.mean,'count':np.sum,target_col:np.mean})\n",
    "    df['ones'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [t[0] for t in processed_video_segments if t[0] in all_ids]\n",
    "video_ids = video_ids + video_ids\n",
    "predictions_df = pd.DataFrame(video_ids,columns=['videoid'])\n",
    "side_col = ['L' if i < len(predictions_df)/2 else 'R' for i in range(len(predictions_df))]\n",
    "predictions_df[target_col] = y\n",
    "predictions_df['side'] = side_col\n",
    "predictions_df = predictions_df.merge(right=datasplit_df[['videoid','dataset']],on=['videoid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(weight_files_df)):\n",
    "    weight_file = weight_files_df['filename'].iloc[i]\n",
    "    print(weight_file)\n",
    "    model.load_weights(checkpoint_folder + \"/%s\" % (weight_file))\n",
    "    preds = model.predict(X)\n",
    "    predictions_df[\"%s_pred_%s\" % (target_col,i)] = undo_scaling(preds[:,0],target_range,target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.groupby(['videoid','side','dataset'],as_index=False).mean().to_csv(\"./data/predictions/cnn_%s_predictions_all_epochs.csv\" % (target_col),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "maps = {\n",
    "    \"GDI\": \"weights-81-72.5151.hdf5\",\n",
    "    \"KneeFlex_maxExtension\": \"weights-27-60.2889.hdf5\",\n",
    "}\n",
    "for col in maps.keys():\n",
    "    model_folder_path = \"./data/models/%s_best.pb\" % (col)\n",
    "    model.load_weights(\"./data/checkpoints/cnn_checkpoints_\" + col + \"/\" + maps[col])\n",
    "    model.save(model_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

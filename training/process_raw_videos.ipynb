{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rn\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from video_process_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "singlesided = False\n",
    "with open('./data/processed/all_videos_dict.pickle', 'rb') as handle:\n",
    "    all_videos = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_df = pd.read_csv('./data/processed/train_test_valid_id_split.csv')\n",
    "datasplit_df['videoid'] = datasplit_df['videoid'].apply(lambda x: int(x))\n",
    "all_ids = datasplit_df['videoid'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_USED = [LANK,RANK,LKNE,RKNE,LHIP,RHIP,LBTO,RBTO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video_and_add_cols(res, swap_orientation = True):\n",
    "    res = res.copy()\n",
    "    centered_filtered = preprocess_frames(res, swap_orientation = swap_orientation)\n",
    "    #add columns\n",
    "    ankle_knee_hip_leftangle = get_angle(LANK,LKNE,LHIP,centered_filtered)\n",
    "    ankle_knee_hip_rightangle = get_angle(RANK,RKNE,RHIP,centered_filtered)\n",
    "    toe_ankle_knee_leftangle = get_angle(LBTO,LANK,LKNE,centered_filtered)\n",
    "    toe_ankle_knee_rightangle = get_angle(RBTO,RANK,RKNE,centered_filtered)\n",
    "    toe_ankle_dist_left = get_distance(LBTO,LANK,centered_filtered)\n",
    "    toe_ankle_dist_right = get_distance(RBTO,RANK,centered_filtered)\n",
    "    lank_rank_xdist = centered_filtered[:,2*RANK] - centered_filtered[:,2*LANK]\n",
    "    rank_lank_xdist = centered_filtered[:,2*LANK] - centered_filtered[:,2*RANK]\n",
    "\n",
    "    for col in [ankle_knee_hip_leftangle,\n",
    "                ankle_knee_hip_rightangle,\n",
    "               toe_ankle_knee_leftangle,\n",
    "               toe_ankle_knee_rightangle,\n",
    "                toe_ankle_dist_left,\n",
    "                toe_ankle_dist_right,\n",
    "               lank_rank_xdist,\n",
    "               rank_lank_xdist]:\n",
    "        centered_filtered = np.append(centered_filtered,col.reshape(-1,1),1)\n",
    "    return centered_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_length = 124\n",
    "processed_videos = []\n",
    "processed_video_segments = []\n",
    "for counter,video_id in enumerate(all_ids):\n",
    "    if(counter % 100 == 0):\n",
    "        print(\"%.2f percent done\" % (counter*100./len(all_ids)))\n",
    "    raw_video = all_videos[video_id]\n",
    "    centered_filtered = process_video_and_add_cols(raw_video, swap_orientation=singlesided)\n",
    "    processed_videos.append((video_id,centered_filtered))\n",
    "    start_idx = 0\n",
    "    for i in range(start_idx,500-vid_length,31):\n",
    "        raw_video_chunk = raw_video[i:i+vid_length,:]\n",
    "        pct_missing =\\\n",
    "            max_pct_nan_or_zero_given_cols(drop_confidence_cols(raw_video_chunk),COLS_USED)\n",
    "        if pct_missing <= 0.25 and len(raw_video_chunk) == vid_length:\n",
    "            processed_video_segments.append((video_id,i,\n",
    "                                     centered_filtered[i:i+vid_length,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_video_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(processed_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffix = \"\"\n",
    "if not singlesided:\n",
    "    suffix = \"_doublesided\"\n",
    "    \n",
    "with open('./data/processed/all_processed_video_segments%s.pickle' % suffix, 'wb') as handle:\n",
    "    pickle.dump(processed_video_segments, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/all_processed_videos%s.pickle' % suffix, 'wb') as handle:\n",
    "    pickle.dump(processed_videos, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = all_videos[list(all_videos.keys())[5]].copy()[:500]\n",
    "num_parts = res.shape[1]/3\n",
    "res = drop_confidence_cols(res)\n",
    "res[res == 0] = np.NaN\n",
    "\n",
    "res = impute_frames(res)\n",
    "res = filter_frames(res)\n",
    "\n",
    "mhip_x = ((res[:,2*RHIP] + res[:,2*LHIP])/2).reshape(-1,1)\n",
    "mhip_y = ((res[:,2*RHIP+1] + res[:,2*LHIP+1])/2).reshape(-1,1)\n",
    "mhip_coords = np.hstack([mhip_x,mhip_y]*int(num_parts))\n",
    "\n",
    "scale_vector_R = np.apply_along_axis(lambda x: np.linalg.norm(x[topoint(RHIP)] -\n",
    "                                                              x[topoint(RKNE)]),1,res)\n",
    "scale_vector_L = np.apply_along_axis(lambda x: np.linalg.norm(x[topoint(LHIP)] -\n",
    "                                                              x[topoint(LKNE)]),1,res)\n",
    "scale_vector = ((scale_vector_R + scale_vector_L)/2.0).reshape(-1,1)\n",
    "\n",
    "res = (res-mhip_coords)/scale_vector\n",
    "#apply the sign\n",
    "lt_x = res[:,2*LANK] - res[:,2*LBTO]\n",
    "rt_x = res[:,2*RANK] - res[:,2*RBTO]\n",
    "signal = (lt_x+rt_x)/2.0\n",
    "orientation = np.where(lt_x+rt_x >= 0,1,-1).reshape(-1,1)\n",
    "\n",
    "even = [2*x for x in range(res.shape[1]//2)]\n",
    "res[:,even] = res[:,even] / orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signal,label=\"ANK_x - BTO_x\")\n",
    "plt.plot(orientation,label=\"orientation\")\n",
    "plt.legend()\n",
    "plt.title(\"Detecting Orientation\")\n",
    "plt.xlabel(\"Frame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(signal,label=\"ANK_x - BTO_x\")\n",
    "plt.plot(res[:,3])\n",
    "plt.xlabel(\"Frame\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

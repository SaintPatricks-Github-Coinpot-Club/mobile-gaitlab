{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(1)\n",
    "rn.seed(1)\n",
    "from keras import backend as K\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "#sess = tf.Session(graph=tf.get_default_graph())\n",
    "#K.set_session(sess)\n",
    "import sys \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv1D,MaxPooling1D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import RMSprop\n",
    "import keras.regularizers\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import linregress\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "import pickle\n",
    "from video_process_utils import *\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"SEMLS_dev_residual\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign train/validation/test ids\n",
    "alldata_processed =\\\n",
    "    pd.read_csv(\"./data/processed/alldata_processed_with_dev_residual.csv\" )\n",
    "alldata_processed['videoid'] = alldata_processed['videoid'].apply(lambda x: int(x))\n",
    "alldata_processed = alldata_processed[alldata_processed[target_col].notnull()]\n",
    "alldata_processed = alldata_processed.groupby(['videoid','side']).head(1)\n",
    "ids_nonmissing_target = set(alldata_processed['videoid'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasplit_df = pd.read_csv('./data/processed/train_test_valid_id_split.csv')\n",
    "datasplit_df['videoid'] = datasplit_df['videoid'].apply(lambda x: int(x))\n",
    "all_ids = set(datasplit_df['videoid']).intersection(ids_nonmissing_target)\n",
    "train_ids = set(datasplit_df[datasplit_df['dataset'] == 'train']['videoid']).intersection(ids_nonmissing_target)\n",
    "validation_ids = set(datasplit_df[datasplit_df['dataset'] == 'validation']['videoid']).intersection(ids_nonmissing_target)\n",
    "test_ids = set(datasplit_df[datasplit_df['dataset'] == 'test']['videoid']).intersection(ids_nonmissing_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/processed/all_processed_video_segments.pickle', 'rb') as handle:\n",
    "    processed_video_segments = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_columns = [2*LANK,2*LANK+1,2*LKNE,2*LKNE+1,\n",
    "        2*LHIP,2*LHIP+1,2*LBTO,2*LBTO+1,\n",
    "                  2*RANK,2*RANK+1,2*RKNE,2*RKNE+1,\n",
    "        2*RHIP,2*RHIP+1,2*RBTO,2*RBTO+1,50,51,52,53,54,55,56]\n",
    "\n",
    "target_dict = {}\n",
    "for i in range(len(alldata_processed)):\n",
    "    row = alldata_processed.iloc[i]\n",
    "    target_dict[row['videoid']] = row[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if target_col == \"gmfcs\":\n",
    "    processed_video_segments = list(filter(lambda x: target_dict[x[0]] in range(1,6), processed_video_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [t[2] for t in processed_video_segments if t[0] in all_ids]\n",
    "X = np.stack(X)[:,:,x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([target_dict[t[0]] for t in processed_video_segments if t[0] in all_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [t[2] for t in processed_video_segments if t[0] in train_ids]\n",
    "X_train = np.stack(X_train)[:,:,x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validation = [t[2] for t in processed_video_segments if t[0] in validation_ids]\n",
    "X_validation = np.stack(X_validation)[:,:,x_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([target_dict[t[0]] for t in processed_video_segments if t[0] in train_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = np.array([target_dict[t[0]] for t in processed_video_segments if t[0] in validation_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoid_count_dict = collections.Counter(np.array([t[0] for t in processed_video_segments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in train_ids]\n",
    "train_videoid_weights = np.array(train_videoid_weights).reshape(-1,1)\n",
    "validation_videoid_weights = [1./videoid_count_dict[t[0]] for t in processed_video_segments if t[0] in validation_ids]\n",
    "validation_videoid_weights = np.array(validation_videoid_weights).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_min = np.min(y_train,axis=0)\n",
    "target_range = np.max(y_train,axis=0) - np.min(y_train,axis=0)\n",
    "print(target_min, target_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scaled = ((y_train-target_min)/target_range).reshape(-1,1)\n",
    "y_validation_scaled = ((y_validation-target_min)/target_range).reshape(-1,1)\n",
    "\n",
    "y_validation_scaled = np.hstack([y_validation_scaled,validation_videoid_weights])\n",
    "y_train_scaled = np.hstack([y_train_scaled,train_videoid_weights])\n",
    "c_i_factor = np.mean(np.vstack([train_videoid_weights,validation_videoid_weights]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_length = 124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_decay(initial_lrate,epochs_drop,drop_factor):\n",
    "    def step_decay_fcn(epoch):\n",
    "        return initial_lrate * math.pow(drop_factor, math.floor((1+epoch)/epochs_drop))\n",
    "    return step_decay_fcn\n",
    "\n",
    "epochs_drop,drop_factor = (10,0.8)\n",
    "initial_lrate = 0.001\n",
    "dropout_amount = 0.5\n",
    "last_layer_dim = 10\n",
    "filter_length = 8\n",
    "conv_dim = 32\n",
    "l2_lambda = 10**(-3.5)\n",
    "\n",
    "def w_mse(weights):\n",
    "    def loss(y_true, y_pred):\n",
    "        #multiply by len(weights) to make the magnitude invariant to number of components in target\n",
    "        return K.mean(K.sum(K.square(y_true-y_pred)*weights,axis=1)*tf.reshape(y_true[:,-1],(-1,1)))/c_i_factor\n",
    "    return loss\n",
    "\n",
    "#we don't want to optimize for the column counting video occurences of course, but\n",
    "#they are included in the target so we can use that column for the loss function\n",
    "weights = [1.0,0]\n",
    "normal_weights = [1.0,0]\n",
    "\n",
    "\n",
    "#normalize weights to sum to 1 to prevent affecting loss function\n",
    "weights = weights/np.sum(weights)\n",
    "normal_weights = normal_weights/np.sum(normal_weights)\n",
    "\n",
    "#fixed epoch budget of 100 that empirically seems to be sufficient \n",
    "n_epochs = 100\n",
    "\n",
    "mse_opt = w_mse(weights)\n",
    "\n",
    "#monitor our actual objective\n",
    "mse_metric = w_mse(target_range**2*normal_weights)\n",
    "\n",
    "hyper_str = \"params_\"\n",
    "for param in [initial_lrate,epochs_drop,drop_factor,dropout_amount,conv_dim,last_layer_dim,filter_length,l2_lambda]:\n",
    "    hyper_str = hyper_str + str(param) + \"_\"\n",
    "\n",
    "K.clear_session()\n",
    "#K.set_session(sess)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(conv_dim,filter_length, input_dim=X_train.shape[2],input_length=vid_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(conv_dim,filter_length,padding='same',kernel_regularizer=keras.regularizers.l2(l2_lambda)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling1D(pool_size=3))\n",
    "model.add(Dropout(dropout_amount))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(last_layer_dim,activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_folder = \"./data/checkpoints/cnn_checkpoints_%s\" % (target_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import TerminateOnNaN\n",
    "\n",
    "train_model = True\n",
    "\n",
    "if not os.path.exists(checkpoint_folder):\n",
    "    os.makedirs(checkpoint_folder)\n",
    "\n",
    "filepath=checkpoint_folder+\"/weights-{epoch:02d}-{val_loss_1:.4f}.hdf5\"\n",
    "if train_model:\n",
    "\n",
    "    opt = RMSprop(lr=0.0,rho=0.9, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss=mse_opt,metrics=[mse_metric],\n",
    "                  optimizer=opt)\n",
    "\n",
    "    checkpoint = \\\n",
    "        ModelCheckpoint(filepath, monitor='val_loss_2', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "\n",
    "    lr = LearningRateScheduler(step_decay(initial_lrate,epochs_drop,drop_factor))\n",
    "\n",
    "    history = model.fit(X_train, y_train_scaled,callbacks=[checkpoint,lr,TerminateOnNaN()],\n",
    "              validation_data=(X_validation,y_validation_scaled),\n",
    "              batch_size=32, epochs=n_epochs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undo_scaling(y,target_range,target_min):\n",
    "    return y*target_range+target_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_files = os.listdir(checkpoint_folder)\n",
    "weight_files_df = pd.DataFrame(weight_files,columns=['filename'])\n",
    "weight_files_df['num'] = weight_files_df['filename'].apply(lambda x: int(x.split('-')[1]))\n",
    "weight_files_df.sort_values(by='num',ascending=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_aggregate_singlevar(y,X,ids,model,target_col):\n",
    "    df = pd.DataFrame(y,columns=[target_col])\n",
    "    target_col_pred = target_col + \"_pred\"\n",
    "    videoids = [t[0] for t in processed_video_segments if t[0] in ids]\n",
    "    df[\"videoid\"] = np.array(videoids)\n",
    "    preds = model.predict(X)\n",
    "    df[target_col_pred] = undo_scaling(preds[:,0],target_range,target_min)\n",
    "    df[\"count\"] = 1\n",
    "    df = df.groupby(['videoid'],as_index=False).agg({target_col_pred:np.mean,'count':np.sum,target_col:np.mean})\n",
    "    df['ones'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = [t[0] for t in processed_video_segments if t[0] in all_ids]\n",
    "predictions_df = pd.DataFrame(video_ids,columns=['videoid'])\n",
    "predictions_df[target_col] = y\n",
    "predictions_df = predictions_df.merge(right=datasplit_df[['videoid','dataset']],on=['videoid'],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(weight_files_df)):\n",
    "    weight_file = weight_files_df['filename'].iloc[i]\n",
    "    print(weight_file)\n",
    "    model.load_weights(checkpoint_folder + \"/%s\" % (weight_file))\n",
    "    preds = model.predict(X)\n",
    "    predictions_df[\"%s_pred_%s\" % (target_col,i)] = undo_scaling(preds[:,0],target_range,target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df.groupby(['videoid','dataset'],as_index=False).mean().to_csv(\"./data/predictions/cnn_%s_singlesided_predictions_all_epochs.csv\" % (target_col),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "# This must be run after finding the best model with select_optimal_epoch \n",
    "maps = {\n",
    "    \"gmfcs\": \"./data/checkpoints/cnn_checkpoints_gmfcs/weights-08-0.5025.hdf5\", #\n",
    "    \"speed\": \"./data/checkpoints/cnn_checkpoints_speed/weights-77-0.0336.hdf5\", #\n",
    "    \"cadence\": \"./data/checkpoints/cnn_checkpoints_cadence/weights-36-0.0211.hdf5\", #\n",
    "    \"SEMLS_dev_residual\": \"./data/checkpoints/cnn_checkpoints_SEMLS_dev_residual/weights-32-0.8929.hdf5\", #\n",
    "#    \"GDI\": \"./data/checkpoints/cnn_checkpoints_GDI/weights-88-72.0330.hdf5\" #\n",
    "    \"GDI\": \"./data/checkpoints/cnn_checkpoints_GDI/weights-92-90.8354.hdf5\" #\n",
    "}\n",
    "for col in maps.keys():\n",
    "    model_folder_path = \"./data/models/%s_best.pb\" % (col)\n",
    "    model.load_weights(maps[col])\n",
    "    model.save(model_folder_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
